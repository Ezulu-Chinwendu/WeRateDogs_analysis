{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "\n",
    "#### By\n",
    " #### Ezulu Priscilla Chinwendu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling, Analysis and Visualization for WeRateDogs Datasets Using Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data wrangling is the process of gathering, cleaning the data and fixing some errors found in the data set. In fulfillment of Udacity  data anlysis curriculum, I gathered, wrangled and analyzed  the WeRateDogs dataset. This Dataset was gathered through the Twitter API . The WeRateDogs Twitter account post pictures and videos of dogs while people rate these dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this analysis, three datasets was used. The first data set is the twitter_archive_enhanced.csv which I gathered from the Udacity platform through manual download. The second dataset is the image_predictions.tsv which i gathered programmatically. The 3rd dataset  is tweet_json.text which I was supposed to gather through the twitter API but because of some challeneges i encountered while creating a twitter developer account, I resolved to using the tweet_json.txt file provided by Udacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this step, I assessed the three datasets for cleanliness and tidyness. The following issues were found in this dataset;\n",
    "\n",
    "#### Quality issues\n",
    "#### 1. In archive_df; in_reply_to_status_id, in_reply_to_user_id have wrong data type. They should be an object instead of a float\n",
    " \n",
    "#### 2. In archive_df, retweeted_status_timestamp datatype should be datetime not float \n",
    "\n",
    "#### 3. In archive_df; under name column, there invalid names such as a, the and so on. They should be replaced with NaN\n",
    "\n",
    "#### 4. In archive_df; some of the rating numerator is greater than the rating denominator which is not supposed to be so \n",
    "\n",
    "#### 5. In archive_df; information on source column is too long \n",
    "\n",
    "#### 6. In image_df; column headers are not descriptive \n",
    "\n",
    "#### 7. In tweet_df; tweet_id, retweet_count, and favorite_count dataypes should be an integer not an object\n",
    "\n",
    "#### 8. In image_df, the naming pattern p1, p2 and p3 columns are inconsistent as some start with capital letters while others start with small letter\n",
    "\n",
    "####  Tidiness issues\n",
    "#### 1. In archive_df; doggo, floofer, pupper and puppo should be merged into one column and categorized as Dog Breed\n",
    "\n",
    "#### 2. In archive_df, column in_reply_to_status_id, in_reply_to_user_id, source, expanded_urls, retweeted_status_id\tretweeted_status_user_id,retweeted_status_timestamp\tshoould be dropped while column jpg_url should be dropped in image_df. Also, tweet_df and image_df should be merged into archive_df dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this step, the issues encounted in step 2 was solved one after the other. Each cleaning included defining the problem, write codes to solve the problem and testing to ensure the issue was resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section, the cleaned master dataset was stored to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After cleaning the data, the new dataset was analyzed to give some insights such as the source of tweets, the distribution of Dog stages according to  likes  and so on. I also Visualized the data to check for correlation between favorite count and retweet count as well as the distribution of count of dog stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
